#load data
train_x_orig, train_y, test_x_orig, test_y, classes = load_data()

# Reshape the training and test examples
train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   
test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T

# Standardize data to have feature values between 0 and 1.
train_x = train_x_flatten/255.
test_x = test_x_flatten/255.

layers_dims = [12288, 20, 7, 5, 1] #  4-layer model

parameters, costs=L_layer_model(train_x_flatten, train_y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False)
plot_costs(costs, learning_rate)
probas, caches = L_model_forward(train_x_flatten, parameters)

# convert probas to 0/1 predictions
m = train_x_flatten.shape[1]
p = np.zeros((1,m))
for i in range(0, probas.shape[1]):
        if probas[0,i] > 0.5:
            p[0,i] = 1
        else:
            p[0,i] = 0
print("Accuracy: "  + str(np.sum((p == y)/m)))      
return p
